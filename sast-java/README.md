### 背景
    目前工业界和学术界均无安全能力的测试评价标准，都是通过在若干样本集上的测试结果对应用安全工具进行评价的。样本集的设计没有标准，差异很大，无法全面客观的反映全貌，且评价结果只能得出一个总体的检出率、遗漏率和误报率数据，无法直观反映安全能力的优势和不足。
    为了能全面而客观的对安全能力进行评价，蚂蚁安全团队从2021年开始探索建立安全能力的评价体系。通过应用安全评价体系项目，希望可以衡量出应用安全产品的技术优劣，指引应用安全产品的发展方向，并可辅助用于商业化安全产品采购的技术选型，详见wiki。
    项目主要包括两部分，一部分是分语言的评价体系，另一部分是基于评价体系的Benchmark。本bundle下发布的是Java SAST引擎能力评价体系V1.0和Benchmark。如果您有任何好的想法，欢迎与我们团队联系。
### 项目结构
```
└── src
    ├── main
    │   ├── java
    │   │   └── com
    │   │       └── sast
    │   │           └── astbenchmark
    │   │               ├── cases   
      
```
### 快速开始
#### 测试流程简介
SAST引擎能力测评包括三步：</br>
（1）准备前置条件</br>
（2）测试目标产品/引擎扫描SAST靶场</br>
（3）自主分析靶场测试结果 或 自动化获取评价体系测试结果（正在建设，还未完全完成） </br>
#### 准备前置条件
（1）确认被测的SAST产品配置了以下sink点规则
```
Runtime.getRuntime().exec() -- 参数位置0
org.apache.http.impl.client.CloseableHttpClient#execute -- 参数位置0
cn.hutool.http.HttpRequest#post -- 参数位置0
java.net.URL#openConnection -- URL对象为污点被调用
java.sql.Statement#executeQuery -- 参数位置0
SinkUtil#sink (本评价体系靶场自定义) -- 参数位置0
```
#### 自主分析靶场测试结果
自主分析测试产品/引擎的输出，结合case路由对应相应的评价项，分析该款产品当前可以检出的场景、不可检出的场景以及存在误报的场景有哪些。从而分析出测试产品/引擎的能力。

#### 自动化获取评价体系测试结果（正在建设，还未完全完成）
当前正在研发基于测试产品的结果自动化生成测试结果的工具，可以自动将SAST产品的输出结果和评价项进行对应并输出测评报告，免去自主分析的繁琐工作。当前正在努力开发中，敬请期待...

### License
This project is licensed under the Apache License 2.0
